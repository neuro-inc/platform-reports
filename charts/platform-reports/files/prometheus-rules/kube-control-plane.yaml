groups:
- name: kubernetes-apps
  rules:
  - alert: KubePodCrashLooping
    annotations:
      description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodcrashlooping
      summary: Pod is crash looping.
    expr: |
      max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
    for: 15m
    labels:
      severity: warning
  - alert: KubePodNotReady
    annotations:
      description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready
      summary: Pod has been in a non-ready state for more than 15 minutes.
    expr: |
      sum by (namespace, pod, cluster) (
        max by(namespace, pod, cluster) (
          kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"}
        ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
          1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
        )
      ) > 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeDeploymentGenerationMismatch
    annotations:
      description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentgenerationmismatch
      summary: Deployment generation mismatch due to possible roll-back
    expr: |
      kube_deployment_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_deployment_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: warning
  - alert: KubeDeploymentReplicasMismatch
    annotations:
      description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentreplicasmismatch
      summary: Deployment has not matched the expected number of replicas.
    expr: |
      (
        kube_deployment_spec_replicas{job="kube-state-metrics"}
          >
        kube_deployment_status_replicas_available{job="kube-state-metrics"}
      ) and (
        changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m])
          ==
        0
      )
    for: 15m
    labels:
      severity: warning
  - alert: KubeDeploymentRolloutStuck
    annotations:
      description: Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentrolloutstuck
      summary: Deployment rollout is not progressing.
    expr: |
      kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics"}
      != 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeStatefulSetReplicasMismatch
    annotations:
      description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetreplicasmismatch
      summary: Deployment has not matched the expected number of replicas.
    expr: |
      (
        kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
          !=
        kube_statefulset_status_replicas{job="kube-state-metrics"}
      ) and (
        changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m])
          ==
        0
      )
    for: 15m
    labels:
      severity: warning
  - alert: KubeStatefulSetGenerationMismatch
    annotations:
      description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetgenerationmismatch
      summary: StatefulSet generation mismatch due to possible roll-back
    expr: |
      kube_statefulset_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_statefulset_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: warning
  - alert: KubeStatefulSetUpdateNotRolledOut
    annotations:
      description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetupdatenotrolledout
      summary: StatefulSet update has not been rolled out.
    expr: |
      (
        max without (revision) (
          kube_statefulset_status_current_revision{job="kube-state-metrics"}
            unless
          kube_statefulset_status_update_revision{job="kube-state-metrics"}
        )
          *
        (
          kube_statefulset_replicas{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
        )
      )  and (
        changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: warning
  - alert: KubeDaemonSetRolloutStuck
    annotations:
      description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetrolloutstuck
      summary: DaemonSet rollout is stuck.
    expr: |
      (
        (
          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        ) or (
          kube_daemonset_status_number_misscheduled{job="kube-state-metrics"}
            !=
          0
        ) or (
          kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        ) or (
          kube_daemonset_status_number_available{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        )
      ) and (
        changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: warning
  - alert: KubeContainerWaiting
    annotations:
      description: pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontainerwaiting
      summary: Pod container waiting longer than 1 hour
    expr: |
      sum by (namespace, pod, container, cluster) (kube_pod_container_status_waiting_reason{job="kube-state-metrics"}) > 0
    for: 1h
    labels:
      severity: warning
  - alert: KubeDaemonSetNotScheduled
    annotations:
      description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetnotscheduled
      summary: DaemonSet pods are not scheduled.
    expr: |
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        -
      kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning
  - alert: KubeDaemonSetMisScheduled
    annotations:
      description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetmisscheduled
      summary: DaemonSet pods are misscheduled.
    expr: |
      kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeJobNotCompleted
    annotations:
      description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobnotcompleted
      summary: Job did not complete in time
    expr: |
      time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"}
        and
      kube_job_status_active{job="kube-state-metrics"} > 0) > 43200
    labels:
      severity: warning
  - alert: KubeJobFailed
    annotations:
      description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobfailed
      summary: Job failed to complete.
    expr: |
      kube_job_failed{job="kube-state-metrics"}  > 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeHpaReplicasMismatch
    annotations:
      description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpareplicasmismatch
      summary: HPA has not matched desired number of replicas.
    expr: |
      (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"}
        !=
      kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"})
        and
      (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        >
      kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"})
        and
      (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        <
      kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"})
        and
      changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeHpaMaxedOut
    annotations:
      description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpamaxedout
      summary: HPA is running at max replicas
    expr: |
      kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        ==
      kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: warning
- name: kubernetes-storage
  rules:
  - alert: KubePersistentVolumeErrors
    annotations:
      description: The persistent volume {{ $labels.persistentvolume }} has status {{ $labels.phase }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeerrors
      summary: PersistentVolume is having issues with provisioning.
    expr: |
      kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
    for: 5m
    labels:
      severity: critical
- name: kubernetes-system
  rules:
  - alert: KubeVersionMismatch
    annotations:
      description: There are {{ $value }} different semantic versions of Kubernetes components running.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeversionmismatch
      summary: Different semantic versions of Kubernetes components running.
    expr: |
      count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
    for: 15m
    labels:
      severity: warning
  - alert: KubeClientErrors
    annotations:
      description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclienterrors
      summary: Kubernetes API server client is experiencing errors.
    expr: |
      (sum(rate(rest_client_requests_total{job="apiserver",code=~"5.."}[5m])) by (cluster, instance, job, namespace)
        /
      sum(rate(rest_client_requests_total{job="apiserver"}[5m])) by (cluster, instance, job, namespace))
      > 0.01
    for: 15m
    labels:
      severity: warning
- name: kubernetes-system-apiserver
  rules:
  - alert: KubeClientCertificateExpiration
    annotations:
      description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 7.0 days.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
      summary: Client certificate is about to expire.
    expr: |
      apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
    for: 5m
    labels:
      severity: warning
  - alert: KubeClientCertificateExpiration
    annotations:
      description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 24.0 hours.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
      summary: Client certificate is about to expire.
    expr: |
      apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
    for: 5m
    labels:
      severity: critical
  - alert: KubeAggregatedAPIErrors
    annotations:
      description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has reported errors. It has appeared unavailable {{ $value | humanize }} times averaged over the past 10m.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapierrors
      summary: Kubernetes aggregated API has reported errors.
    expr: |
      sum by(name, namespace, cluster)(increase(aggregator_unavailable_apiservice_total{job="apiserver"}[10m])) > 4
    labels:
      severity: warning
  - alert: KubeAggregatedAPIDown
    annotations:
      description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has been only {{ $value | humanize }}% available over the last 10m.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapidown
      summary: Kubernetes aggregated API is down.
    expr: |
      (1 - max by(name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice{job="apiserver"}[10m]))) * 100 < 85
    for: 5m
    labels:
      severity: warning
  - alert: KubeAPIDown
    annotations:
      description: KubeAPI has disappeared from Prometheus target discovery.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapidown
      summary: Target disappeared from Prometheus target discovery.
    expr: |
      absent(up{job="apiserver"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeAPITerminatedRequests
    annotations:
      description: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapiterminatedrequests
      summary: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
    expr: |
      sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m]))  / (  sum(rate(apiserver_request_total{job="apiserver"}[10m])) + sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m])) ) > 0.20
    for: 5m
    labels:
      severity: warning
- name: kubernetes-system-kubelet
  rules:
  - alert: KubeNodeNotReady
    annotations:
      description: '{{ $labels.node }} has been unready for more than 15 minutes.'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodenotready
      summary: Node is not ready.
    expr: |
      kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeNodeUnreachable
    annotations:
      description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodeunreachable
      summary: Node is unreachable.
    expr: |
      (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
    for: 15m
    labels:
      severity: warning
  - alert: KubeletTooManyPods
    annotations:
      description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubelettoomanypods
      summary: Kubelet is running at capacity.
    expr: |
      count by(cluster, node) (
        (kube_pod_status_phase{job="kube-state-metrics",phase="Running"} == 1) * on(instance,pod,namespace,cluster) group_left(node) topk by(instance,pod,namespace,cluster) (1, kube_pod_info{job="kube-state-metrics"})
      )
      /
      max by(cluster, node) (
        kube_node_status_capacity{job="kube-state-metrics",resource="pods"} != 1
      ) > 0.95
    for: 15m
    labels:
      severity: info
  - alert: KubeNodeReadinessFlapping
    annotations:
      description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodereadinessflapping
      summary: Node readiness status is flapping.
    expr: |
      sum(changes(kube_node_status_condition{job="kube-state-metrics",status="true",condition="Ready"}[15m])) by (cluster, node) > 2
    for: 15m
    labels:
      severity: warning
  - alert: KubeletPlegDurationHigh
    annotations:
      description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletplegdurationhigh
      summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
    expr: |
      node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
    for: 5m
    labels:
      severity: warning
  - alert: KubeletPodStartUpLatencyHigh
    annotations:
      description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletpodstartuplatencyhigh
      summary: Kubelet Pod startup latency is too high.
    expr: |
      histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le)) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"} > 60
    for: 15m
    labels:
      severity: warning
  - alert: KubeletClientCertificateExpiration
    annotations:
      description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
      summary: Kubelet client certificate is about to expire.
    expr: |
      kubelet_certificate_manager_client_ttl_seconds < 604800
    labels:
      severity: warning
  - alert: KubeletClientCertificateExpiration
    annotations:
      description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
      summary: Kubelet client certificate is about to expire.
    expr: |
      kubelet_certificate_manager_client_ttl_seconds < 86400
    labels:
      severity: critical
  - alert: KubeletServerCertificateExpiration
    annotations:
      description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
      summary: Kubelet server certificate is about to expire.
    expr: |
      kubelet_certificate_manager_server_ttl_seconds < 604800
    labels:
      severity: warning
  - alert: KubeletServerCertificateExpiration
    annotations:
      description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
      summary: Kubelet server certificate is about to expire.
    expr: |
      kubelet_certificate_manager_server_ttl_seconds < 86400
    labels:
      severity: critical
  - alert: KubeletClientCertificateRenewalErrors
    annotations:
      description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificaterenewalerrors
      summary: Kubelet has failed to renew its client certificate.
    expr: |
      increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeletServerCertificateRenewalErrors
    annotations:
      description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificaterenewalerrors
      summary: Kubelet has failed to renew its server certificate.
    expr: |
      increase(kubelet_server_expiration_renew_errors[5m]) > 0
    for: 15m
    labels:
      severity: warning
  - alert: KubeletDown
    annotations:
      description: Kubelet has disappeared from Prometheus target discovery.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletdown
      summary: Target disappeared from Prometheus target discovery.
    expr: |
      absent(up{job="kubelet", metrics_path="/metrics"} == 1)
    for: 15m
    labels:
      severity: critical
- name: kubelet.rules
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
    labels:
      quantile: "0.99"
    record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
    labels:
      quantile: "0.9"
    record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
    labels:
      quantile: "0.5"
    record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
